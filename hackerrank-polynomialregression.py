# PROBLEM STATEMENT:
"""
Charlie wants to purchase office-space. He does a detailed survey of the offices and corporate complexes in the area, and tries to quantify a lot of factors, such as the distance of the offices from residential and other commercial areas, schools and workplaces; the reputation of the construction companies and builders involved in constructing the apartments; the distance of the offices from highways, freeways and important roads; the facilities around the office space and so on.

Each of these factors are quantified, normalized and mapped to values on a scale of 0 to 1. Charlie then makes a table. Each row in the table corresponds to Charlie's observations for a particular house. If Charlie has observed and noted F features, the row contains F values separated by a single space, followed by the office-space price in dollars/square-foot. If Charlie makes observations for H houses, his observation table has (F+1) columns and H rows, and a total of (F+1) * H entries.

Charlie does several such surveys and provides you with the tabulated data. At the end of these tables are some rows which have just F columns (the price per square foot is missing). Your task is to predict these prices. F can be any integer number between 1 and 5, both inclusive.

There is one important observation which Charlie has made.

The prices per square foot, are (approximately) a polynomial function of the features in the observation table. This polynomial always has an order less than 4
Input Format

The first line contains two space separated integers, F and N. Over here, F is the number of observed features. N is the number of rows for which features as well as price per square-foot have been noted.
This is followed by a table having F+1 columns and N rows with each row in a new line and each column separated by a single space. The last column is the price per square foot.

The table is immediately followed by integer T followed by T rows containing F columns.
"""

#--------------------------------------------------------------------------------------------------------------------------

# -*- coding: utf-8 -*-
"""hackerrank-polyreg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ntc2aBM5JjZm5SAckMtdzUarLxmIrIRf
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import PolynomialFeatures

filepath = "/content/hackerrank-polynomialregression.txt"
with open(filepath, 'r') as file:
  lines = file.readlines()

F,N = map(int, lines[0].split())
print("F: ", F)
print("N: ",N)

F = 2  # Number of features
X_train = np.array([row[:F] for row in traindata])  # Features
y_train = np.array([row[F] for row in traindata])   # Target

# Print the shapes to verify
print("Shape of X_train:", X_train.shape)  # Should be (N, F) -> (100, 2)
print("Shape of y_train:", y_train.shape)  # Should be (N,)   -> (100,)

print(X_train.shape)
print(y_train.shape)
print(xtest.shape)

traindata = [list(map(float, line.split())) for line in lines[1:N+1]]
testdata = [list(map(float, line.split())) for line in lines[N+2:]]

print("First 5 rows of train_data:")
for row in traindata[:5]:
    print(row)
print("\nFirst 5 rows of test_data:")
for row in testdata[:5]:
    print(row)

X_test = np.array(testdata)

X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42
)

degree = 3
poly = PolynomialFeatures(degree=degree)
X_train_poly = poly.fit_transform(X_train_split)
X_val_poly = poly.transform(X_val_split)
X_test_poly = poly.transform(X_test)

print("Shape of X_train_poly:", X_train_poly.shape)
print("Shape of X_val_poly:", X_val_poly.shape)
print("Shape of X_test_poly:", X_test_poly.shape)
print("Shape of y_train_split:", y_train_split.shape)
print("Shape of y_val_split:", y_val_split.shape)

model = LinearRegression()
model.fit(X_train_poly, y_train_split)

v_val_pred = model.predict(X_val_poly)
mse = mean_squared_error(y_val_split, v_val_pred)
r2 = r2_score(y_val_split, v_val_pred)
print(f"Validation Mean Squared Error: {mse:.2f}")
print("R2 score: ", r2)

y_test_pred = model.predict(X_test_poly)
print("Predictions for test data:")
for pred in y_test_pred:
    print(f"{pred:.2f}")

plt.figure(figsize=(10, 6))
plt.plot(y_test_pred, label="Predicted Values")
plt.xlabel("Data Point Index")
plt.ylabel("Predicted Value")
plt.title(f"Predictions for Test Data (R2 Score: {r2:.2f})")
plt.legend()
plt.grid(True)
plt.show()


#--------------------------------------------------------------------------------------------------------------------------
#METHOD 2:

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd

F,N=map(int,input().split())
train_data= []
for i in range(N):
    rows=list(map(float,input().split()))
    train_data.append(rows)
T = int(input())
test_data=[list(map(float,input().split())) for _ in range(T)]

X_train=[]
y_train=[]
for row in train_data:
    X_train.append(row[:F]) 
    y_train.append(row[F]) 

X_train = np.array(X_train) 
X_test=np.array(test_data)
#print(X_test)

poly=PolynomialFeatures(degree=3)
X_train_poly=poly.fit_transform(X_train)
X_test_poly=poly.transform(X_test)

model=LinearRegression()
model.fit(X_train_poly,y_train)
y_pred=model.predict(X_test_poly)

for pred in y_pred:
    print(pred)
